{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train = pd.read_csv(\"C:/Users/hclsa/Desktop/Fall2019/CMPE188/TeamProject/raw_data/weather_train.csv\")\n",
    "weather_test = pd.read_csv(\"C:/Users/hclsa/Desktop/Fall2019/CMPE188/TeamProject/raw_data/weather_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing values in precip_depth_1_hr that have a '-1' reading with '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.loc[weather_train['precip_depth_1_hr'] < 0, 'precip_depth_1_hr'] = 0\n",
    "weather_test.loc[weather_test['precip_depth_1_hr'] < 0, 'precip_depth_1_hr'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the Timestamp and Site ID, as we do not want to do preprocessing on it yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_trainTime = weather_train['timestamp'].copy()\n",
    "weather_trainSiteID = weather_train['site_id'].copy()\n",
    "weather_trainToImpute = weather_train.drop(['timestamp', 'site_id'], axis=1)\n",
    "# ===================================\n",
    "weather_testTime = weather_test['timestamp'].copy()\n",
    "weather_testSiteID = weather_test['site_id'].copy()\n",
    "weather_testToImpute = weather_test.drop(['timestamp', 'site_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we impute the NaN values of all columns with the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanImputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "weather_trainImputed = meanImputer.fit_transform(weather_trainToImpute)\n",
    "weather_trainImputed = pd.DataFrame(weather_trainImputed, columns = weather_trainToImpute.columns)\n",
    "# ===================================\n",
    "weather_testImputed = meanImputer.fit_transform(weather_testToImpute)\n",
    "weather_testImputed = pd.DataFrame(weather_testImputed, columns = weather_testToImpute.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do min max scaling (normalizing to [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "minMaxScaler = preprocessing.MinMaxScaler()\n",
    "weather_trainImputedScaled = minMaxScaler.fit_transform(weather_trainImputed)\n",
    "weather_trainImputedScaled = pd.DataFrame(weather_trainImputedScaled, columns = weather_trainImputed.columns)\n",
    "# ===================================\n",
    "weather_testImputedScaled = minMaxScaler.fit_transform(weather_testImputed)\n",
    "weather_testImputedScaled = pd.DataFrame(weather_testImputedScaled, columns = weather_testImputed.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we join the timestamp, site ID and all the imputed/scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_trainFinal = pd.concat([weather_trainTime, weather_trainSiteID], axis=1)\n",
    "weather_trainFinal = pd.concat([weather_trainFinal, weather_trainImputedScaled], axis=1)\n",
    "# ===================================\n",
    "weather_testFinal = pd.concat([weather_testTime, weather_testSiteID], axis=1)\n",
    "weather_testFinal = pd.concat([weather_testFinal, weather_testImputedScaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the dataframe as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_trainFinal.to_csv('weather_train_preprocessed.csv', index = False)\n",
    "weather_testFinal.to_csv('weather_test_preprocessed.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_trainFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_teainFinal.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
